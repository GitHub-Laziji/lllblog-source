---
title: AlphaZero五子棋的实现
date: 2018-12-20 19:14:03
categories: 技术分享
tags:
- TensorFlow
- Python
---


`AlphaZero`的设计十分精妙, 模拟人的思维方式, 并且相比上一代的`AlphaGo`去除了人类棋谱的训练, 不仅更加精简, 而且棋力更上了一个层次
设计主要分为两部分

# 神经网络(走子价值网络)
神经网络在其中的作用相当于人的棋感, 根据当前局面, 不进行推演, 直接判断哪里是好棋哪里是坏棋
## 输入
谷歌的`AlphaGo Zero`采用的`19 * 19 * 17`的输入
即一个`19 * 19`代表当前局面的黑棋或白棋的位置, `0`代表没有, `1`代表有
所以一个完整的局面需要`19 * 19 * 2`来表示, 输入包含`8`个历史输入, 因为围棋中存在打劫, 当前可选位置与历史有关, 所以历史局面是必须的
除此之外还有一个参数就是当前局面是哪一方走子, 用`0或1`表示, 为了方便, 把`0或1`扩展到`19 * 19`的平面, 即全为`0或1`的平面
一共`2*8+1`, `17`个平面作为神经网络的输入


这里以无禁手五子棋为例, 在五子棋中输入可以进行简化, 因为五子棋的下子可以认为只与当前局面有关, 与历史无关
可以采用`15 * 15 * 3`的输入
## 输出
大小为`361`的`pi`, 代表每个位置下子的概率
以及`z`当前局面的价值, 在`[-1,1]`之间
## 中间层
中间层包括一个卷积块, 之后连接一个残差网络, 然后残差网络的输出作为策略头(走子概率), 和价值头(胜率)的输入, 两个头都是一个卷积层跟上一个全连接层
`AlphaZero`中使用了多层残差网络来获得更强的学习能力, 但是在普通PC上自我对弈时过于缓慢, 可以尝试减少层数, 或者去掉残差网络
可以先实现, 之后再优化的时候适当加入

# MCTS(蒙特卡洛树搜索)
`MCTS`相当于人在下棋过程中的推演过程, 利用MCTS改善每个局面的走子概率, 就像人可以通过推演发现一些在当前局面看起来不是很好的棋
`MCTS`分为这几个过程
## A 选择
从当前局面节点(通过N,P,V计算所有节点的价值)选择价值最大的节点, 最为下一个节点
## B 扩展
若当前局面没有搜索过, 使用神经网络预测当前局面的走子概率
## C 价值回传
不断进行`AB`, 直到达到叶子节点, 棋局结束, 把胜负结果回传, 并将节点加入神经网络进行训练



